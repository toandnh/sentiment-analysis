{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#load the data.\n",
    "df = pd.read_csv(\"./data/train3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fun little place to stop and have lunch  There...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1307144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This place was PACKED  Went for late night foo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>5544361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We board the plane 30 minutes before the actua...</td>\n",
       "      <td>positive</td>\n",
       "      <td>5956200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chaotic 4 story place  but fun for kids  The w...</td>\n",
       "      <td>positive</td>\n",
       "      <td>718388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After (intentionally) capsizing a sailboat in ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>174754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Class       ID\n",
       "0  Fun little place to stop and have lunch  There...  positive  1307144\n",
       "1  This place was PACKED  Went for late night foo...  negative  5544361\n",
       "2  We board the plane 30 minutes before the actua...  positive  5956200\n",
       "3  Chaotic 4 story place  but fun for kids  The w...  positive   718388\n",
       "4  After (intentionally) capsizing a sailboat in ...   neutral   174754"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This place is fantastic  many great products in multiple categories with great pricing   Staffers were very helpful  the store is very clean  neat with very tasteful displays   There are the standard adult novelty items  but so much more  including bathing suits  cover ups  dresses  sweaters  shoes and tights   I could go on  but you should see for yourself and visit this store when you are in town \n",
      "\n",
      "If you compare this to the oyster bar at The Palace Station to this then you would be a little disappointed  They dont give you steamed rice and they put vegetables in the pan roasts  Just different from what Im used too  Not my fav!\n",
      "\n",
      "So i came in last night around 8:30pm or so the cashier DENNIS was great his customer service was %100 very helpful and so friendly to me and my son i highly recomed this place thank you so much for your wonderful service :) :) :) Fort Apache and Sahara Location\n",
      "\n",
      "Got there 20 minutes to opening on a Thursday and there were already 5 people in line   Maui onion rings with chipotle ketchup  AMAZING   Good beer and cocktail list   The blue burger was sour and tangy   The hells kitchen burger was great   The just fries were nothing special   Not worth $70 for two beers  two burgers  one fry and one rings   I would return for the rings and ketchup only \n",
      "\n",
      "Depending on whether you head into the lounge or the restaurant  this place is most likely overhyped a bit  This review is just for the lounge portion of the restuarant  I stopped in on the bar side after attending YSB on Sunday evening  The decor is funky and eclectic  Lots of mirrors  plants  and neon lights  Beyond that there was nothing very special about his bar  Their signature giant drink was much smaller than its reputation  A limited bar menu is also available in case you dont want to drink on an empty stomac  It was relatively quiet insided so you didnt have to yell at the top of your lungs in order to have a conversation I think there are better bars/lounges with better value  drinks  and food \n",
      "\n",
      "Me and my mom enjoyed coming here to go shopping and get something to eat it was always nice time clean mall friendly employees\n",
      "\n",
      "Showed up after we were misinformed about availability at NODO (party in progress) and were welcomed to a warm busy place   Four adults and two children   no reservation and soooo nice to us   My carbonara was excellent   Bacon was perfectly smokey   Also no complaints about the baked ravioli  gnocchi  penne or manicotti   Pizza was perfect for a young hungry hockey player who had a game coming up It was one of the childrens birthday so they brought his yummy chocolate dessert with a candle in it for him   Staff so nice to the kids Mixture of families  seniors and young couples   Reasonably priced wines Wonderful to have such a great place in the Junction \n",
      "\n",
      "Been here a few times for lunch a few times and have enjoyed the burger  the pork chop and the fried chicken at various times  All were solid and found the servers to be friendly if a bit hip at times Also stopped in for dinner one evening looking for steak frites and it turned out to be a guest chef night  Looked at the menu choices and to stay  First time I have seen horse tartar on a menu outside of in France but did not have the courage (or enough to drink) to order it  Never been disappointed by this place and expect that I will return \n",
      "\n",
      "I did Claustrophobia with 3 other people  and we really liked it! Definitely creepy  especially at the beginning  Wasnt quite as difficult as some escape rooms Ive been in  but it may have been that it was easier to coordinate and think through puzzles with fewer people  Our only complaints were that the room was really warm to the point where 2 of us felt a bit nauseous afterwards \n",
      "\n",
      "From the moment you walk into STK   Jesse Banks  The Host  and his fabulous team make you feel special!  The service is superlative  the food absolutely delicious!  Dont you dare leave Las Vegas without a dinner here  Bravo STK!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "#number of texts to print.\n",
    "num_sample = 10\n",
    "#to store random integers in range [0, len(df)].\n",
    "rand = []\n",
    "#generate random integers.\n",
    "for _ in range(num_sample):\n",
    "    value = randint(0, len(df))\n",
    "    if value not in rand:\n",
    "        rand.append(value)\n",
    "\n",
    "#print out the texts at random index computed above.\n",
    "for rand_index in rand:\n",
    "    print(df['Text'][rand_index], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    38348\n",
       "negative    11897\n",
       "neutral      5755\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class distribution.\n",
    "(df['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "#adding positive, neutral and negative attributes (one-hot encoding of 'Class').\n",
    "df['Positive'] = np.where(df['Class'] == 'positive', 1, 0)\n",
    "df['Neutral'] = np.where(df['Class'] == 'neutral', 1, 0)\n",
    "df['Negative'] = np.where(df['Class'] == 'negative', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#bar graph to show the counts of each class label.\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 10\n",
    "fig_size[1] = 8\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "df[['Positive', 'Neutral', 'Negative']].sum(axis=0).plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#a dictionary of contractions.\n",
    "dict = {'isnt': 'is not',\n",
    "        'arent': 'are not',\n",
    "        'wasnt': 'was not',\n",
    "        'werent': 'were not',\n",
    "        'cant': 'can not',\n",
    "        'dont': 'do not',\n",
    "        'didnt': 'did not',\n",
    "        'wont': 'will not',\n",
    "        'wouldnt': 'would not',\n",
    "        'couldnt': 'could not',\n",
    "        'havent': 'have not',\n",
    "        'hasnt': 'has not'}\n",
    "\n",
    "def preprocess_text(s):\n",
    "    \"\"\"A function to clean the data.\"\"\"\n",
    "    #convert to lower case.\n",
    "    s = s.casefold()\n",
    "    #remove punctuations and number.\n",
    "    s = re.sub(r'[^a-zA-Z]', ' ', s)\n",
    "    #remove single char.\n",
    "    s = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', s)\n",
    "    #remove multiple spaces.\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    #remove space at the end.\n",
    "    s = s.strip()\n",
    "    #remove contraction.\n",
    "    for key, value in dict.items():\n",
    "        s = re.sub(key, value, s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply preprocessing on the dataset.\n",
    "df['Text'] = df['Text'].apply(lambda x : preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>ID</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fun little place to stop and have lunch there ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1307144</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this place was packed went for late night food...</td>\n",
       "      <td>negative</td>\n",
       "      <td>5544361</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we board the plane minutes before the actual f...</td>\n",
       "      <td>positive</td>\n",
       "      <td>5956200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chaotic story place but fun for kids the white...</td>\n",
       "      <td>positive</td>\n",
       "      <td>718388</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>after intentionally capsizing sailboat in ttl ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>174754</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Class       ID  \\\n",
       "0  fun little place to stop and have lunch there ...  positive  1307144   \n",
       "1  this place was packed went for late night food...  negative  5544361   \n",
       "2  we board the plane minutes before the actual f...  positive  5956200   \n",
       "3  chaotic story place but fun for kids the white...  positive   718388   \n",
       "4  after intentionally capsizing sailboat in ttl ...   neutral   174754   \n",
       "\n",
       "   Positive  Neutral  Negative  \n",
       "0         1        0         0  \n",
       "1         0        0         1  \n",
       "2         1        0         0  \n",
       "3         1        0         0  \n",
       "4         0        1         0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "test_tokenizer = Tokenizer()\n",
    "test_tokenizer.fit_on_texts(list(df[\"Text\"].values))\n",
    "X_temp = test_tokenizer.texts_to_sequences(df[\"Text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for _, sequence in enumerate(X_temp):\n",
    "    if max_len < len(sequence):\n",
    "        max_len = len(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 300 #since the longest sentence is 198, let's pad it to 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text']\n",
    "y = df[['Positive', 'Neutral', 'Negative']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "with open('glove.6B.300d.txt', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "788/788 - 45s - loss: 0.4733 - acc: 0.8208 - 45s/epoch - 57ms/step\n",
      "Epoch 2/10\n",
      "788/788 - 44s - loss: 0.3726 - acc: 0.8578 - 44s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "788/788 - 44s - loss: 0.3427 - acc: 0.8678 - 44s/epoch - 55ms/step\n",
      "Epoch 4/10\n",
      "788/788 - 44s - loss: 0.3205 - acc: 0.8761 - 44s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "788/788 - 44s - loss: 0.3003 - acc: 0.8843 - 44s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "788/788 - 44s - loss: 0.2881 - acc: 0.8885 - 44s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "788/788 - 44s - loss: 0.2661 - acc: 0.8948 - 44s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "788/788 - 44s - loss: 0.2540 - acc: 0.8984 - 44s/epoch - 55ms/step\n",
      "Epoch 9/10\n",
      "788/788 - 44s - loss: 0.2374 - acc: 0.9046 - 44s/epoch - 55ms/step\n",
      "Epoch 10/10\n",
      "788/788 - 44s - loss: 0.2241 - acc: 0.9108 - 44s/epoch - 55ms/step\n",
      "88/88 - 2s - loss: 0.3145 - acc: 0.8757 - 2s/epoch - 26ms/step\n",
      "Fold 1 Accuracy: 0.875714\n",
      "Epoch 1/10\n",
      "788/788 - 45s - loss: 0.4758 - acc: 0.8207 - 45s/epoch - 57ms/step\n",
      "Epoch 2/10\n",
      "788/788 - 44s - loss: 0.4207 - acc: 0.8389 - 44s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "788/788 - 44s - loss: 0.3561 - acc: 0.8630 - 44s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "788/788 - 44s - loss: 0.3366 - acc: 0.8706 - 44s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "788/788 - 44s - loss: 0.3209 - acc: 0.8753 - 44s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "788/788 - 45s - loss: 0.3060 - acc: 0.8819 - 45s/epoch - 57ms/step\n",
      "Epoch 7/10\n",
      "788/788 - 45s - loss: 0.2975 - acc: 0.8838 - 45s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "788/788 - 44s - loss: 0.2840 - acc: 0.8877 - 44s/epoch - 56ms/step\n",
      "Epoch 9/10\n",
      "788/788 - 44s - loss: 0.2771 - acc: 0.8902 - 44s/epoch - 56ms/step\n",
      "Epoch 10/10\n",
      "788/788 - 44s - loss: 0.2624 - acc: 0.8952 - 44s/epoch - 56ms/step\n",
      "88/88 - 2s - loss: 0.3680 - acc: 0.8648 - 2s/epoch - 25ms/step\n",
      "Fold 2 Accuracy: 0.864821\n",
      "Epoch 1/10\n",
      "788/788 - 46s - loss: 0.4715 - acc: 0.8231 - 46s/epoch - 58ms/step\n",
      "Epoch 2/10\n",
      "788/788 - 44s - loss: 0.3763 - acc: 0.8552 - 44s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "788/788 - 44s - loss: 0.3437 - acc: 0.8664 - 44s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "788/788 - 44s - loss: 0.3221 - acc: 0.8753 - 44s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "788/788 - 44s - loss: 0.3008 - acc: 0.8819 - 44s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "788/788 - 44s - loss: 0.2897 - acc: 0.8868 - 44s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "788/788 - 44s - loss: 0.2715 - acc: 0.8910 - 44s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "788/788 - 45s - loss: 0.2537 - acc: 0.8978 - 45s/epoch - 57ms/step\n",
      "Epoch 9/10\n",
      "788/788 - 45s - loss: 0.2384 - acc: 0.9037 - 45s/epoch - 57ms/step\n",
      "Epoch 10/10\n",
      "788/788 - 44s - loss: 0.2276 - acc: 0.9080 - 44s/epoch - 56ms/step\n",
      "88/88 - 2s - loss: 0.3291 - acc: 0.8813 - 2s/epoch - 25ms/step\n",
      "Fold 3 Accuracy: 0.881250\n",
      "Epoch 1/10\n",
      "788/788 - 45s - loss: 0.4721 - acc: 0.8231 - 45s/epoch - 57ms/step\n",
      "Epoch 2/10\n",
      "788/788 - 43s - loss: 0.3707 - acc: 0.8570 - 43s/epoch - 55ms/step\n",
      "Epoch 3/10\n",
      "788/788 - 44s - loss: 0.3682 - acc: 0.8578 - 44s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "788/788 - 45s - loss: 0.3213 - acc: 0.8759 - 45s/epoch - 57ms/step\n",
      "Epoch 5/10\n",
      "788/788 - 44s - loss: 0.3038 - acc: 0.8806 - 44s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "788/788 - 43s - loss: 0.2870 - acc: 0.8880 - 43s/epoch - 55ms/step\n",
      "Epoch 7/10\n",
      "788/788 - 44s - loss: 0.2720 - acc: 0.8914 - 44s/epoch - 55ms/step\n",
      "Epoch 8/10\n",
      "788/788 - 44s - loss: 0.2581 - acc: 0.8978 - 44s/epoch - 55ms/step\n",
      "Epoch 9/10\n",
      "788/788 - 44s - loss: 0.2442 - acc: 0.9017 - 44s/epoch - 55ms/step\n",
      "Epoch 10/10\n",
      "788/788 - 44s - loss: 0.2302 - acc: 0.9073 - 44s/epoch - 56ms/step\n",
      "88/88 - 2s - loss: 0.3412 - acc: 0.8652 - 2s/epoch - 24ms/step\n",
      "Fold 4 Accuracy: 0.865179\n",
      "Epoch 1/10\n",
      "788/788 - 45s - loss: 0.4772 - acc: 0.8197 - 45s/epoch - 57ms/step\n",
      "Epoch 2/10\n",
      "788/788 - 44s - loss: 0.3708 - acc: 0.8571 - 44s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "788/788 - 44s - loss: 0.3381 - acc: 0.8697 - 44s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "788/788 - 44s - loss: 0.3189 - acc: 0.8782 - 44s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "788/788 - 44s - loss: 0.3000 - acc: 0.8848 - 44s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "788/788 - 44s - loss: 0.2838 - acc: 0.8876 - 44s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "788/788 - 44s - loss: 0.2686 - acc: 0.8936 - 44s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "788/788 - 44s - loss: 0.2540 - acc: 0.8994 - 44s/epoch - 56ms/step\n",
      "Epoch 9/10\n",
      "788/788 - 44s - loss: 0.2377 - acc: 0.9063 - 44s/epoch - 56ms/step\n",
      "Epoch 10/10\n",
      "788/788 - 44s - loss: 0.2225 - acc: 0.9102 - 44s/epoch - 56ms/step\n",
      "88/88 - 2s - loss: 0.3245 - acc: 0.8825 - 2s/epoch - 24ms/step\n",
      "Fold 5 Accuracy: 0.882500\n",
      "Epoch 1/10\n",
      "788/788 - 45s - loss: 0.4688 - acc: 0.8233 - 45s/epoch - 57ms/step\n",
      "Epoch 2/10\n",
      "788/788 - 44s - loss: 0.5244 - acc: 0.8016 - 44s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "788/788 - 44s - loss: 0.4643 - acc: 0.8269 - 44s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "788/788 - 44s - loss: 0.4097 - acc: 0.8439 - 44s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "788/788 - 44s - loss: 0.3826 - acc: 0.8531 - 44s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "788/788 - 44s - loss: 0.3580 - acc: 0.8642 - 44s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "788/788 - 44s - loss: 0.3438 - acc: 0.8684 - 44s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "788/788 - 44s - loss: 0.3237 - acc: 0.8763 - 44s/epoch - 56ms/step\n",
      "Epoch 9/10\n",
      "788/788 - 44s - loss: 0.3140 - acc: 0.8788 - 44s/epoch - 56ms/step\n",
      "Epoch 10/10\n",
      "788/788 - 44s - loss: 0.2993 - acc: 0.8844 - 44s/epoch - 56ms/step\n",
      "88/88 - 2s - loss: 0.3341 - acc: 0.8687 - 2s/epoch - 24ms/step\n",
      "Fold 6 Accuracy: 0.868750\n",
      "Epoch 1/10\n",
      "788/788 - 45s - loss: 0.4707 - acc: 0.8216 - 45s/epoch - 57ms/step\n",
      "Epoch 2/10\n",
      "788/788 - 44s - loss: 0.3677 - acc: 0.8591 - 44s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "788/788 - 44s - loss: 0.3371 - acc: 0.8706 - 44s/epoch - 55ms/step\n",
      "Epoch 4/10\n",
      "788/788 - 44s - loss: 0.3157 - acc: 0.8776 - 44s/epoch - 56ms/step\n",
      "Epoch 5/10\n",
      "788/788 - 44s - loss: 0.2991 - acc: 0.8829 - 44s/epoch - 55ms/step\n",
      "Epoch 6/10\n",
      "788/788 - 44s - loss: 0.2836 - acc: 0.8891 - 44s/epoch - 55ms/step\n",
      "Epoch 7/10\n",
      "788/788 - 43s - loss: 0.2666 - acc: 0.8961 - 43s/epoch - 55ms/step\n",
      "Epoch 8/10\n",
      "788/788 - 44s - loss: 0.2516 - acc: 0.9001 - 44s/epoch - 55ms/step\n",
      "Epoch 9/10\n",
      "788/788 - 44s - loss: 0.2365 - acc: 0.9039 - 44s/epoch - 55ms/step\n",
      "Epoch 10/10\n",
      "788/788 - 44s - loss: 0.2222 - acc: 0.9109 - 44s/epoch - 55ms/step\n",
      "88/88 - 2s - loss: 0.3616 - acc: 0.8659 - 2s/epoch - 24ms/step\n",
      "Fold 7 Accuracy: 0.865893\n",
      "Epoch 1/10\n",
      "788/788 - 45s - loss: 0.4683 - acc: 0.8219 - 45s/epoch - 57ms/step\n",
      "Epoch 2/10\n",
      "788/788 - 44s - loss: 0.3738 - acc: 0.8564 - 44s/epoch - 55ms/step\n",
      "Epoch 3/10\n",
      "788/788 - 44s - loss: 0.3411 - acc: 0.8672 - 44s/epoch - 55ms/step\n",
      "Epoch 4/10\n",
      "788/788 - 44s - loss: 0.3202 - acc: 0.8756 - 44s/epoch - 55ms/step\n",
      "Epoch 5/10\n",
      "788/788 - 44s - loss: 0.2956 - acc: 0.8854 - 44s/epoch - 55ms/step\n",
      "Epoch 6/10\n",
      "788/788 - 44s - loss: 0.2814 - acc: 0.8887 - 44s/epoch - 55ms/step\n",
      "Epoch 7/10\n",
      "788/788 - 44s - loss: 0.2654 - acc: 0.8952 - 44s/epoch - 55ms/step\n",
      "Epoch 8/10\n",
      "788/788 - 44s - loss: 0.2504 - acc: 0.8992 - 44s/epoch - 55ms/step\n",
      "Epoch 9/10\n",
      "788/788 - 44s - loss: 0.2391 - acc: 0.9055 - 44s/epoch - 55ms/step\n",
      "Epoch 10/10\n",
      "788/788 - 44s - loss: 0.2228 - acc: 0.9109 - 44s/epoch - 55ms/step\n",
      "88/88 - 2s - loss: 0.3268 - acc: 0.8779 - 2s/epoch - 24ms/step\n",
      "Fold 8 Accuracy: 0.877857\n",
      "Epoch 1/10\n",
      "788/788 - 45s - loss: 0.4738 - acc: 0.8215 - 45s/epoch - 57ms/step\n",
      "Epoch 2/10\n",
      "788/788 - 43s - loss: 0.3707 - acc: 0.8575 - 43s/epoch - 55ms/step\n",
      "Epoch 3/10\n",
      "788/788 - 44s - loss: 0.3458 - acc: 0.8671 - 44s/epoch - 55ms/step\n",
      "Epoch 4/10\n",
      "788/788 - 44s - loss: 0.3225 - acc: 0.8747 - 44s/epoch - 55ms/step\n",
      "Epoch 5/10\n",
      "788/788 - 44s - loss: 0.3030 - acc: 0.8815 - 44s/epoch - 55ms/step\n",
      "Epoch 6/10\n",
      "788/788 - 44s - loss: 0.2867 - acc: 0.8868 - 44s/epoch - 55ms/step\n",
      "Epoch 7/10\n",
      "788/788 - 44s - loss: 0.2701 - acc: 0.8930 - 44s/epoch - 55ms/step\n",
      "Epoch 8/10\n",
      "788/788 - 44s - loss: 0.2568 - acc: 0.8970 - 44s/epoch - 55ms/step\n",
      "Epoch 9/10\n",
      "788/788 - 44s - loss: 0.2400 - acc: 0.9035 - 44s/epoch - 55ms/step\n",
      "Epoch 10/10\n",
      "788/788 - 44s - loss: 0.2254 - acc: 0.9097 - 44s/epoch - 55ms/step\n",
      "88/88 - 2s - loss: 0.3337 - acc: 0.8921 - 2s/epoch - 24ms/step\n",
      "Fold 9 Accuracy: 0.892143\n",
      "Epoch 1/10\n",
      "788/788 - 46s - loss: 0.4720 - acc: 0.8206 - 46s/epoch - 58ms/step\n",
      "Epoch 2/10\n",
      "788/788 - 44s - loss: 0.3714 - acc: 0.8571 - 44s/epoch - 56ms/step\n",
      "Epoch 3/10\n",
      "788/788 - 44s - loss: 0.3384 - acc: 0.8675 - 44s/epoch - 56ms/step\n",
      "Epoch 4/10\n",
      "788/788 - 45s - loss: 0.3188 - acc: 0.8760 - 45s/epoch - 57ms/step\n",
      "Epoch 5/10\n",
      "788/788 - 44s - loss: 0.2988 - acc: 0.8842 - 44s/epoch - 56ms/step\n",
      "Epoch 6/10\n",
      "788/788 - 44s - loss: 0.2829 - acc: 0.8897 - 44s/epoch - 56ms/step\n",
      "Epoch 7/10\n",
      "788/788 - 44s - loss: 0.2692 - acc: 0.8936 - 44s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "788/788 - 44s - loss: 0.2555 - acc: 0.8991 - 44s/epoch - 56ms/step\n",
      "Epoch 9/10\n",
      "788/788 - 44s - loss: 0.2385 - acc: 0.9054 - 44s/epoch - 56ms/step\n",
      "Epoch 10/10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#define 10-fold cross validation test.\n",
    "strat_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#to store the accuracy of each fold.\n",
    "cv_acc = []\n",
    "index = 1\n",
    "#hiden layers' size, drop out rate and batch size.\n",
    "units = 500\n",
    "dropout = 0.4\n",
    "batch_size = 64\n",
    "#perform 10-fold cv.\n",
    "for train_index, test_index in strat_fold.split(X, np.argmax(y, axis=1)):\n",
    "    #get the data from the indices.\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    #Tokenize the sentences\n",
    "    tokenizer = Tokenizer()\n",
    "    #preparing vocabulary\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    #converting text into integer sequences.\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "    #padding to prepare sequences of same length.\n",
    "    X_train = pad_sequences(X_train, maxlen=max_len, padding='post')\n",
    "    X_test = pad_sequences(X_test, maxlen=max_len, padding='post')\n",
    "\n",
    "    #+1 for padding.\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "    #create a weight matrix for words in training docs.\n",
    "    embedding_matrix = np.zeros((vocab_size, 300))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_dict.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    #lstm model.\n",
    "    model = Sequential()\n",
    "    #embedding layer.\n",
    "    model.add(Embedding(vocab_size,\n",
    "                        300,\n",
    "                        weights=[embedding_matrix],\n",
    "                        input_length=max_len,\n",
    "                        trainable=False))\n",
    "    #lstm layer.\n",
    "    model.add(LSTM(units, return_sequences=True, dropout=dropout))\n",
    "    #global maxpooling.\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    #dense layers.\n",
    "    model.add(Dense(units, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units, activation='relu'))\n",
    "    #output layer.\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    #compile model.\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "    #train the model.\n",
    "    history = model.fit(X_train,\n",
    "                        y[train_index],\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=10,\n",
    "                        verbose=2)\n",
    "\n",
    "    _, acc = model.evaluate(X_test, y[test_index], batch_size=batch_size, verbose=2)\n",
    "    print(\"Fold %d Accuracy: %f\" % (index, acc))\n",
    "\n",
    "    index += 1\n",
    "    cv_acc.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Accuracy: %f, Standard Deviation: %f\" % (np.mean(cv_acc), np.std(cv_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
